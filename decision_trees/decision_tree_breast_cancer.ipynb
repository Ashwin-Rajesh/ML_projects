{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbasecondae136968380ae4fcdb1cae1051555e6d5",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Decision trees on iris dataset\n",
    "\n",
    "The iris dataset contains sepal length, sepal width, petal length and petal width for classifying flowers between 3 classes. \n",
    "\n",
    "Here, we will be using decision trees to classify a given input into one of the 3 classes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "\n",
    "## Importing libraries and data pre-processing\n",
    "\n",
    "Libraries :\n",
    "- sklearn\n",
    "  - Importing iris dataset\n",
    "  - Splitting dataset into train and test sets\n",
    "- pandas\n",
    "  - Dataset is stored as pandas dataframe\n",
    "- numpy\n",
    "- matplotlib\n",
    "  - For visualisation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn for only the dataset, pandas for managing the dataset and numpy for processing\n",
    "from sklearn.datasets import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "### About the dataset\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>25.380</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>24.990</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>23.570</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>14.910</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>22.540</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>0.1726</td>\n      <td>0.05623</td>\n      <td>...</td>\n      <td>25.450</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>0.1752</td>\n      <td>0.05533</td>\n      <td>...</td>\n      <td>23.690</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>0.1590</td>\n      <td>0.05648</td>\n      <td>...</td>\n      <td>18.980</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>0.2397</td>\n      <td>0.07016</td>\n      <td>...</td>\n      <td>25.740</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.1587</td>\n      <td>0.05884</td>\n      <td>...</td>\n      <td>9.456</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows Ã— 30 columns</p>\n</div>",
      "text/plain": "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n0          17.99         10.38          122.80     1001.0          0.11840   \n1          20.57         17.77          132.90     1326.0          0.08474   \n2          19.69         21.25          130.00     1203.0          0.10960   \n3          11.42         20.38           77.58      386.1          0.14250   \n4          20.29         14.34          135.10     1297.0          0.10030   \n..           ...           ...             ...        ...              ...   \n564        21.56         22.39          142.00     1479.0          0.11100   \n565        20.13         28.25          131.20     1261.0          0.09780   \n566        16.60         28.08          108.30      858.1          0.08455   \n567        20.60         29.33          140.10     1265.0          0.11780   \n568         7.76         24.54           47.92      181.0          0.05263   \n\n     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0             0.27760         0.30010              0.14710         0.2419   \n1             0.07864         0.08690              0.07017         0.1812   \n2             0.15990         0.19740              0.12790         0.2069   \n3             0.28390         0.24140              0.10520         0.2597   \n4             0.13280         0.19800              0.10430         0.1809   \n..                ...             ...                  ...            ...   \n564           0.11590         0.24390              0.13890         0.1726   \n565           0.10340         0.14400              0.09791         0.1752   \n566           0.10230         0.09251              0.05302         0.1590   \n567           0.27700         0.35140              0.15200         0.2397   \n568           0.04362         0.00000              0.00000         0.1587   \n\n     mean fractal dimension  ...  worst radius  worst texture  \\\n0                   0.07871  ...        25.380          17.33   \n1                   0.05667  ...        24.990          23.41   \n2                   0.05999  ...        23.570          25.53   \n3                   0.09744  ...        14.910          26.50   \n4                   0.05883  ...        22.540          16.67   \n..                      ...  ...           ...            ...   \n564                 0.05623  ...        25.450          26.40   \n565                 0.05533  ...        23.690          38.25   \n566                 0.05648  ...        18.980          34.12   \n567                 0.07016  ...        25.740          39.42   \n568                 0.05884  ...         9.456          30.37   \n\n     worst perimeter  worst area  worst smoothness  worst compactness  \\\n0             184.60      2019.0           0.16220            0.66560   \n1             158.80      1956.0           0.12380            0.18660   \n2             152.50      1709.0           0.14440            0.42450   \n3              98.87       567.7           0.20980            0.86630   \n4             152.20      1575.0           0.13740            0.20500   \n..               ...         ...               ...                ...   \n564           166.10      2027.0           0.14100            0.21130   \n565           155.00      1731.0           0.11660            0.19220   \n566           126.70      1124.0           0.11390            0.30940   \n567           184.60      1821.0           0.16500            0.86810   \n568            59.16       268.6           0.08996            0.06444   \n\n     worst concavity  worst concave points  worst symmetry  \\\n0             0.7119                0.2654          0.4601   \n1             0.2416                0.1860          0.2750   \n2             0.4504                0.2430          0.3613   \n3             0.6869                0.2575          0.6638   \n4             0.4000                0.1625          0.2364   \n..               ...                   ...             ...   \n564           0.4107                0.2216          0.2060   \n565           0.3215                0.1628          0.2572   \n566           0.3403                0.1418          0.2218   \n567           0.9387                0.2650          0.4087   \n568           0.0000                0.0000          0.2871   \n\n     worst fractal dimension  \n0                    0.11890  \n1                    0.08902  \n2                    0.08758  \n3                    0.17300  \n4                    0.07678  \n..                       ...  \n564                  0.07115  \n565                  0.06637  \n566                  0.07820  \n567                  0.12400  \n568                  0.07039  \n\n[569 rows x 30 columns]"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "x = data['data']\n",
    "y = data['target']\n",
    "col_names = data['feature_names']\n",
    "\n",
    "x = pd.DataFrame(x, columns=col_names)\n",
    "display(x)\n",
    "x['target'] = y\n",
    "\n",
    "tgt_types = x['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "train, test = train_test_split(x, test_size=60)"
   ]
  },
  {
   "source": [
    "## The code!\n",
    "I have used an object-oriented approach, and have implemented a class for each node in the decision tree (inspired by keras and pytorch APIs). The tree is build using a recursive breadth-first search algorithm, while simultaneously fitting the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(x, col_name=None, thresh_val=None, debug=False):\n",
    "    \n",
    "    if(col_name == None):\n",
    "        tot_no = x.shape[0]\n",
    "        class_loss = np.zeros((tgt_types.size,1))\n",
    "        \n",
    "        for i in range(tgt_types.size):\n",
    "            class_no = x.loc[x['target'] == tgt_types[i]].shape[0]\n",
    "            class_p  = class_no / tot_no\n",
    "            class_loss[i, 0] = class_p * (1 - class_p)\n",
    "\n",
    "        return sum(class_loss)\n",
    "\n",
    "    upper = x.loc[x[col_name] >  thresh_val]\n",
    "    lower = x.loc[x[col_name] <= thresh_val]\n",
    "\n",
    "\n",
    "    class_loss = np.zeros((tgt_types.size, 2))\n",
    "\n",
    "    upper_tot = upper.shape[0]   \n",
    "    lower_tot = lower.shape[0] \n",
    "\n",
    "    if(upper_tot == 0 or lower_tot == 0):\n",
    "        return 1\n",
    "\n",
    "    for i in range(tgt_types.size):\n",
    "        upper_cls_no = upper.loc[upper['target'] == tgt_types[i]].shape[0]\n",
    "        lower_cls_no = lower.loc[lower['target'] == tgt_types[i]].shape[0]\n",
    "        \n",
    "        upper_cls_p  = upper_cls_no / upper_tot\n",
    "        lower_cls_p  = lower_cls_no / lower_tot\n",
    "\n",
    "        class_loss[i, 0] = upper_cls_p * (1 - upper_cls_p)\n",
    "        class_loss[i, 1] = lower_cls_p * (1 - lower_cls_p)\n",
    "\n",
    "    gini = np.sum(class_loss, axis=0)\n",
    "\n",
    "    impurity = (upper_tot*gini[0]/x.shape[0]) + (lower_tot*gini[1]/x.shape[0])\n",
    "\n",
    "    if debug:\n",
    "        plt.scatter(upper[col_name], upper['target'], color=\"green\")\n",
    "        plt.scatter(lower[col_name], lower['target'], color=\"blue\")\n",
    "        plt.ylabel(\"Class\")\n",
    "        plt.xlabel(col_name)\n",
    "        plt.axline((thresh_val, 0), (thresh_val, 2))\n",
    "        plt.title(\"Split : %.2f, Impurity : %.3f\"%(thresh_val, impurity))\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, col_name, thresh):\n",
    "    upper = x.loc[x[col_name] > thresh].drop(col_name, axis=1)\n",
    "    lower = x.loc[x[col_name] <= thresh].drop(col_name, axis=1)\n",
    "\n",
    "    return (upper, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(x):\n",
    "    inputs = x.drop('target', axis=1)\n",
    "    outputs = x['target']\n",
    "    \n",
    "    min_impurity = 1\n",
    "    min_col = \"\"\n",
    "    min_thresh = -1\n",
    "\n",
    "    for col_name in inputs.columns:\n",
    "\n",
    "        values = x.sort_values(col_name)[col_name].unique()\n",
    "        thresholds = [(values[i]+values[i+1])/2 for i in range(values.shape[0]-1)]\n",
    "\n",
    "        for i in thresholds:\n",
    "            impurity = gini(x, col_name, i, False)\n",
    "\n",
    "            if(impurity < min_impurity):\n",
    "                min_impurity = impurity\n",
    "                min_col      = col_name\n",
    "                min_thresh   = i\n",
    "\n",
    "    return (min_impurity, min_col, min_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode():\n",
    "    def __init__(self, parent, level=None, name=None, debug=False):\n",
    "        self.parent = parent\n",
    "        \n",
    "        if(level == None):\n",
    "            if(parent == None):\n",
    "                self.level = 0\n",
    "            else:\n",
    "                self.level = parent.level + 1\n",
    "        else:\n",
    "            self.level = level\n",
    "        \n",
    "        self.leaf   = False             # Is this node a leaf node?\n",
    "        self.state  = None              # The output state (if a leaf node)\n",
    "        self.col    = None              # Threshold column name\n",
    "        self.thresh = 0                 # Threshold value\n",
    "        \n",
    "        self.upper  = None              # Upper child node\n",
    "        self.lower  = None              # Lower child node\n",
    "\n",
    "        self.debug  = debug             # If true, displays debug information\n",
    "\n",
    "        if(name == None):               # The name is displayed if debug is turned on\n",
    "            if(parent == None):\n",
    "                self.name = \"root_node\"\n",
    "            else:\n",
    "                self.name = \"level%d_node\" % self.level\n",
    "        else:\n",
    "            self.name = name\n",
    "\n",
    "        if(debug):\n",
    "            print(\" %15s : Initialised node with level : %2d\" % (self.name, self.level))\n",
    "\n",
    "    # Turn the node into a leaf node, with provided output\n",
    "    def make_leaf(self, output):\n",
    "        self.leaf  = True\n",
    "        self.state = output\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Made into leaf node, with output '%d'\" % (self.name, self.state))\n",
    "\n",
    "    # Train with data (set column and threshold).\n",
    "    # If the gini impurity has deteriorated or has not improved, then the node is made into a leaf node.\n",
    "    # force_decision can be set to True to disable automatic conversion to leaf nodes\n",
    "    def train(self, x, force_decision=False):\n",
    "        data_impurity = gini(x)\n",
    "        impurity, self.col, self.thresh = find_best_split(x)\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Trained. Impurity before : %.2f, Impurity : %.2f, Column : '%s', Threshold : %.2f\" % (self.name, data_impurity, impurity, self.col, self.thresh))\n",
    "        \n",
    "        if(impurity >= data_impurity and not force_decision):\n",
    "            self.make_leaf(x.mode()['target'][0])\n",
    "            self.col    = None\n",
    "            self.thresh = None\n",
    "\n",
    "    # Split the data into two, if its not a leaf node\n",
    "    def split(self, x):\n",
    "        if(self.leaf):\n",
    "            if(self.debug):\n",
    "                print(\" %15s : Cant split, is a leaf node.\"%self.name)\n",
    "            return False\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Splitting input...\"%self.name)\n",
    "        \n",
    "        return split_data(x, self.col, self.thresh)\n",
    "    \n",
    "    # Attach the upper child node\n",
    "    def attach_upper(self, upper_node):\n",
    "        if(self.leaf):\n",
    "            print(\" %15s : Cant attach, is a leaf node\"%self.name)\n",
    "            return False\n",
    "        \n",
    "        self.upper = upper_node\n",
    "        return True\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Attached upper node '%s'\"%(self.name, self.upper.name))\n",
    "\n",
    "    # Attach the lower child node\n",
    "    def attach_lower(self, lower_node):\n",
    "        if(self.leaf):\n",
    "            print(\" %15s : Cant attach, is a leaf node\"%self.name)\n",
    "            return False\n",
    "\n",
    "        self.lower = lower_node\n",
    "        return True\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Attached upper node '%s'\"%(self.name, self.lower.name))\n",
    "\n",
    "    # Classify a given data sample\n",
    "    # If the node is a leaf node, it returns the assigned state\n",
    "    # Else, it uses the decision criteria to call either the upper or lower child node.\n",
    "    def classify(self, x):\n",
    "        if(self.leaf):\n",
    "            if(self.debug):\n",
    "                print(\" %15s : Leaf node - returning result %d\"%(self.name, self.state))\n",
    "            return self.state\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Classifying criteria - %s >= %.2f\"%(self.name, self.col, self.thresh))\n",
    "        if(x[self.col] > self.thresh):\n",
    "            if(self.debug):\n",
    "                print(\" %15s : Moving to upper node\"%self.name)\n",
    "            return self.upper.classify(x)\n",
    "        else:\n",
    "            if(self.debug):\n",
    "                print(\" %15s : Moving to lower node\"%self.name)\n",
    "            return self.lower.classify(x)\n",
    "\n",
    "    # Create and link upper and lower child nodes\n",
    "    def make_children(self, debug=None):\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Making children nodes...\"%self.name)\n",
    "\n",
    "        if(debug==None):\n",
    "            debug=self.debug\n",
    "\n",
    "        upper = DecisionNode(self, name='%s+'%(self.name), debug=debug)\n",
    "        lower = DecisionNode(self, name='%s-'%(self.name), debug=debug)\n",
    "\n",
    "        self.attach_upper(upper)\n",
    "        self.attach_lower(lower)\n",
    "\n",
    "        return upper, lower\n",
    "\n",
    "    # Returns the upper and lower child nodes\n",
    "    def get_children(self):\n",
    "        return self.upper, self.lower\n",
    "\n",
    "    # Change debug state.\n",
    "    # Setting propagate to True will propagate the change in debug state down its child nodes.\n",
    "    def set_debug(self, debug=True, propagate=False):\n",
    "        if(self.debug != debug):\n",
    "            print(\" %15s : Setting debug to %s\"%(self.name, debug))\n",
    "        self.debug=debug\n",
    "        if(propagate):\n",
    "            if(not self.leaf):\n",
    "                self.upper.set_debug(debug, True)\n",
    "                self.lower.set_debug(debug, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurseive depth-first search, while building the tree\n",
    "def build_tree(data, level, node=None, debug=False):\n",
    "    # If at the last level, make the node a leaf node\n",
    "    if(level == 0):\n",
    "        leaf_out = data.mode()['target'][0]\n",
    "        node.make_leaf(leaf_out)\n",
    "        return\n",
    "    \n",
    "    # If no parent node is passed, create a new node, called the 'root' node.\n",
    "    if(node == None):\n",
    "        node = DecisionNode(None, name='root', debug=debug)\n",
    "    \n",
    "    # Train the node\n",
    "    node.train(data)\n",
    "    \n",
    "    # If the node decided to be a leaf node, stop building further\n",
    "    if(node.leaf):\n",
    "        return\n",
    "\n",
    "    # Else, make child nodes, and split the dataset between these nodes\n",
    "    node.make_children()\n",
    "    upper_ds, lower_ds = node.split(data)\n",
    "    \n",
    "    # Build the tree down from these nodes, using the split dataset.\n",
    "    # Note : Its a depth-first search because the upper node is called first, and only after\n",
    "    #   its tree has been built, is the lower node called\n",
    "    build_tree(upper_ds, level-1, node.upper)\n",
    "    build_tree(lower_ds, level-1, node.lower)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            root : Initialised node with level :  0\n",
      "            root : Trained. Impurity before : 0.47, Impurity : 0.14, Column : 'worst radius', Threshold : 16.80\n",
      "            root : Making children nodes...\n",
      "           root+ : Initialised node with level :  1\n",
      "           root- : Initialised node with level :  1\n",
      "            root : Splitting input...\n",
      "           root+ : Trained. Impurity before : 0.11, Impurity : 0.06, Column : 'mean texture', Threshold : 14.99\n",
      "           root+ : Making children nodes...\n",
      "          root++ : Initialised node with level :  2\n",
      "          root+- : Initialised node with level :  2\n",
      "           root+ : Splitting input...\n",
      "          root++ : Trained. Impurity before : 0.04, Impurity : 0.02, Column : 'worst concavity', Threshold : 0.22\n",
      "          root++ : Making children nodes...\n",
      "         root+++ : Initialised node with level :  3\n",
      "         root++- : Initialised node with level :  3\n",
      "          root++ : Splitting input...\n",
      "         root+++ : Trained. Impurity before : 0.00, Impurity : 0.00, Column : 'mean radius', Threshold : 12.26\n",
      "         root+++ : Made into leaf node, with output '0'\n",
      "         root++- : Trained. Impurity before : 0.47, Impurity : 0.00, Column : 'compactness error', Threshold : 0.02\n",
      "         root++- : Making children nodes...\n",
      "        root++-+ : Initialised node with level :  4\n",
      "        root++-- : Initialised node with level :  4\n",
      "         root++- : Splitting input...\n",
      "        root++-+ : Trained. Impurity before : 0.00, Impurity : 0.00, Column : 'mean radius', Threshold : 16.34\n",
      "        root++-+ : Made into leaf node, with output '1'\n",
      "        root++-- : Trained. Impurity before : 0.00, Impurity : 0.00, Column : 'mean radius', Threshold : 15.57\n",
      "        root++-- : Made into leaf node, with output '0'\n",
      "          root+- : Trained. Impurity before : 0.42, Impurity : 0.00, Column : 'mean compactness', Threshold : 0.13\n",
      "          root+- : Making children nodes...\n",
      "         root+-+ : Initialised node with level :  3\n",
      "         root+-- : Initialised node with level :  3\n",
      "          root+- : Splitting input...\n",
      "         root+-+ : Trained. Impurity before : 0.00, Impurity : 0.00, Column : 'mean radius', Threshold : 15.40\n",
      "         root+-+ : Made into leaf node, with output '0'\n",
      "         root+-- : Trained. Impurity before : 0.00, Impurity : 0.00, Column : 'mean radius', Threshold : 14.84\n",
      "         root+-- : Made into leaf node, with output '1'\n",
      "           root- : Trained. Impurity before : 0.16, Impurity : 0.09, Column : 'worst concave points', Threshold : 0.14\n",
      "           root- : Making children nodes...\n",
      "          root-+ : Initialised node with level :  2\n",
      "          root-- : Initialised node with level :  2\n",
      "           root- : Splitting input...\n",
      "          root-+ : Trained. Impurity before : 0.49, Impurity : 0.24, Column : 'worst texture', Threshold : 27.38\n",
      "          root-+ : Making children nodes...\n",
      "         root-++ : Initialised node with level :  3\n",
      "         root-+- : Initialised node with level :  3\n",
      "          root-+ : Splitting input...\n",
      "         root-++ : Trained. Impurity before : 0.00, Impurity : 0.00, Column : 'mean radius', Threshold : 11.02\n",
      "         root-++ : Made into leaf node, with output '0'\n",
      "         root-+- : Trained. Impurity before : 0.41, Impurity : 0.27, Column : 'worst area', Threshold : 730.10\n",
      "         root-+- : Making children nodes...\n",
      "        root-+-+ : Initialised node with level :  4\n",
      "        root-+-- : Initialised node with level :  4\n",
      "         root-+- : Splitting input...\n",
      "        root-+-+ : Trained. Impurity before : 0.50, Impurity : 0.13, Column : 'mean radius', Threshold : 14.19\n",
      "        root-+-+ : Making children nodes...\n",
      "       root-+-++ : Initialised node with level :  5\n",
      "       root-+-+- : Initialised node with level :  5\n",
      "        root-+-+ : Splitting input...\n",
      "       root-+-++ : Made into leaf node, with output '1'\n",
      "       root-+-+- : Made into leaf node, with output '0'\n",
      "        root-+-- : Trained. Impurity before : 0.00, Impurity : 0.00, Column : 'mean radius', Threshold : 9.38\n",
      "        root-+-- : Made into leaf node, with output '1'\n",
      "          root-- : Trained. Impurity before : 0.03, Impurity : 0.03, Column : 'radius error', Threshold : 1.05\n",
      "          root-- : Making children nodes...\n",
      "         root--+ : Initialised node with level :  3\n",
      "         root--- : Initialised node with level :  3\n",
      "          root-- : Splitting input...\n",
      "         root--+ : Trained. Impurity before : 0.00, Impurity : 1.00, Column : '', Threshold : -1.00\n",
      "         root--+ : Made into leaf node, with output '0'\n",
      "         root--- : Trained. Impurity before : 0.03, Impurity : 0.02, Column : 'area error', Threshold : 38.61\n",
      "         root--- : Making children nodes...\n",
      "        root---+ : Initialised node with level :  4\n",
      "        root---- : Initialised node with level :  4\n",
      "         root--- : Splitting input...\n",
      "        root---+ : Trained. Impurity before : 0.28, Impurity : 0.15, Column : 'mean compactness', Threshold : 0.06\n",
      "        root---+ : Making children nodes...\n",
      "       root---++ : Initialised node with level :  5\n",
      "       root---+- : Initialised node with level :  5\n",
      "        root---+ : Splitting input...\n",
      "       root---++ : Made into leaf node, with output '1'\n",
      "       root---+- : Made into leaf node, with output '0'\n",
      "        root---- : Trained. Impurity before : 0.01, Impurity : 0.01, Column : 'smoothness error', Threshold : 0.00\n",
      "        root---- : Making children nodes...\n",
      "       root----+ : Initialised node with level :  5\n",
      "       root----- : Initialised node with level :  5\n",
      "        root---- : Splitting input...\n",
      "       root----+ : Made into leaf node, with output '1'\n",
      "       root----- : Made into leaf node, with output '1'\n",
      " Fitting data took 113.391 seconds\n"
     ]
    }
   ],
   "source": [
    "# The level is the maximum number of decision nodes from root to the end (excluding leaf nodes)\n",
    "tick = time()\n",
    "root = build_tree(train, 5, debug=True)\n",
    "print(\" Fitting data took %.3f seconds\"%(time()-tick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Testing on a sample : test set index '22'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "mean radius                 12.720000\nmean texture                17.670000\nmean perimeter              80.980000\nmean area                  501.300000\nmean smoothness              0.078960\nmean compactness             0.045220\nmean concavity               0.014020\nmean concave points          0.018350\nmean symmetry                0.145900\nmean fractal dimension       0.055440\nradius error                 0.295400\ntexture error                0.883600\nperimeter error              2.109000\narea error                  23.240000\nsmoothness error             0.007337\ncompactness error            0.011740\nconcavity error              0.005383\nconcave points error         0.005623\nsymmetry error               0.019400\nfractal dimension error      0.001180\nworst radius                13.820000\nworst texture               20.960000\nworst perimeter             88.870000\nworst area                 586.800000\nworst smoothness             0.106800\nworst compactness            0.096050\nworst concavity              0.034690\nworst concave points         0.036120\nworst symmetry               0.216500\nworst fractal dimension      0.060250\ntarget                       1.000000\nName: 429, dtype: float64"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            root : Classifying criteria - worst radius >= 16.80\n            root : Moving to lower node\n           root- : Classifying criteria - worst concave points >= 0.14\n           root- : Moving to lower node\n          root-- : Classifying criteria - radius error >= 1.05\n          root-- : Moving to lower node\n         root--- : Classifying criteria - area error >= 38.61\n         root--- : Moving to lower node\n        root---- : Classifying criteria - smoothness error >= 0.00\n        root---- : Moving to upper node\n       root----+ : Leaf node - returning result 1\n\n Classification result : 1, Label : 1\n\n Testing on a sample : test set index '44'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "mean radius                  19.020000\nmean texture                 24.590000\nmean perimeter              122.000000\nmean area                  1076.000000\nmean smoothness               0.090290\nmean compactness              0.120600\nmean concavity                0.146800\nmean concave points           0.082710\nmean symmetry                 0.195300\nmean fractal dimension        0.056290\nradius error                  0.549500\ntexture error                 0.663600\nperimeter error               3.055000\narea error                   57.650000\nsmoothness error              0.003872\ncompactness error             0.018420\nconcavity error               0.037100\nconcave points error          0.012000\nsymmetry error                0.019640\nfractal dimension error       0.003337\nworst radius                 24.560000\nworst texture                30.410000\nworst perimeter             152.900000\nworst area                 1623.000000\nworst smoothness              0.124900\nworst compactness             0.320600\nworst concavity               0.575500\nworst concave points          0.195600\nworst symmetry                0.395600\nworst fractal dimension       0.092880\ntarget                        0.000000\nName: 87, dtype: float64"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            root : Classifying criteria - worst radius >= 16.80\n            root : Moving to upper node\n           root+ : Classifying criteria - mean texture >= 14.99\n           root+ : Moving to upper node\n          root++ : Classifying criteria - worst concavity >= 0.22\n          root++ : Moving to upper node\n         root+++ : Leaf node - returning result 0\n\n Classification result : 0, Label : 0\n\n Testing on a sample : test set index '55'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "mean radius                  19.730000\nmean texture                 19.820000\nmean perimeter              130.700000\nmean area                  1206.000000\nmean smoothness               0.106200\nmean compactness              0.184900\nmean concavity                0.241700\nmean concave points           0.097400\nmean symmetry                 0.173300\nmean fractal dimension        0.066970\nradius error                  0.766100\ntexture error                 0.780000\nperimeter error               4.115000\narea error                   92.810000\nsmoothness error              0.008482\ncompactness error             0.050570\nconcavity error               0.068000\nconcave points error          0.019710\nsymmetry error                0.014670\nfractal dimension error       0.007259\nworst radius                 25.280000\nworst texture                25.590000\nworst perimeter             159.800000\nworst area                 1933.000000\nworst smoothness              0.171000\nworst compactness             0.595500\nworst concavity               0.848900\nworst concave points          0.250700\nworst symmetry                0.274900\nworst fractal dimension       0.129700\ntarget                        0.000000\nName: 252, dtype: float64"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            root : Classifying criteria - worst radius >= 16.80\n            root : Moving to upper node\n           root+ : Classifying criteria - mean texture >= 14.99\n           root+ : Moving to upper node\n          root++ : Classifying criteria - worst concavity >= 0.22\n          root++ : Moving to upper node\n         root+++ : Leaf node - returning result 0\n\n Classification result : 0, Label : 0\n\n Testing on a sample : test set index '47'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "mean radius                 12.470000\nmean texture                18.600000\nmean perimeter              81.090000\nmean area                  481.900000\nmean smoothness              0.099650\nmean compactness             0.105800\nmean concavity               0.080050\nmean concave points          0.038210\nmean symmetry                0.192500\nmean fractal dimension       0.063730\nradius error                 0.396100\ntexture error                1.044000\nperimeter error              2.497000\narea error                  30.290000\nsmoothness error             0.006953\ncompactness error            0.019110\nconcavity error              0.027010\nconcave points error         0.010370\nsymmetry error               0.017820\nfractal dimension error      0.003586\nworst radius                14.970000\nworst texture               24.640000\nworst perimeter             96.050000\nworst area                 677.900000\nworst smoothness             0.142600\nworst compactness            0.237800\nworst concavity              0.267100\nworst concave points         0.101500\nworst symmetry               0.301400\nworst fractal dimension      0.087500\ntarget                       1.000000\nName: 204, dtype: float64"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            root : Classifying criteria - worst radius >= 16.80\n            root : Moving to lower node\n           root- : Classifying criteria - worst concave points >= 0.14\n           root- : Moving to lower node\n          root-- : Classifying criteria - radius error >= 1.05\n          root-- : Moving to lower node\n         root--- : Classifying criteria - area error >= 38.61\n         root--- : Moving to lower node\n        root---- : Classifying criteria - smoothness error >= 0.00\n        root---- : Moving to upper node\n       root----+ : Leaf node - returning result 1\n\n Classification result : 1, Label : 1\n\n Testing on a sample : test set index '36'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "mean radius                  18.310000\nmean texture                 20.580000\nmean perimeter              120.800000\nmean area                  1052.000000\nmean smoothness               0.106800\nmean compactness              0.124800\nmean concavity                0.156900\nmean concave points           0.094510\nmean symmetry                 0.186000\nmean fractal dimension        0.059410\nradius error                  0.544900\ntexture error                 0.922500\nperimeter error               3.218000\narea error                   67.360000\nsmoothness error              0.006176\ncompactness error             0.018770\nconcavity error               0.029130\nconcave points error          0.010460\nsymmetry error                0.015590\nfractal dimension error       0.002725\nworst radius                 21.860000\nworst texture                26.200000\nworst perimeter             142.200000\nworst area                 1493.000000\nworst smoothness              0.149200\nworst compactness             0.253600\nworst concavity               0.375900\nworst concave points          0.151000\nworst symmetry                0.307400\nworst fractal dimension       0.078630\ntarget                        0.000000\nName: 516, dtype: float64"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            root : Classifying criteria - worst radius >= 16.80\n            root : Moving to upper node\n           root+ : Classifying criteria - mean texture >= 14.99\n           root+ : Moving to upper node\n          root++ : Classifying criteria - worst concavity >= 0.22\n          root++ : Moving to upper node\n         root+++ : Leaf node - returning result 0\n\n Classification result : 0, Label : 0\n\n            root : Setting debug to False\n           root+ : Setting debug to False\n          root++ : Setting debug to False\n         root+++ : Setting debug to False\n         root++- : Setting debug to False\n        root++-+ : Setting debug to False\n        root++-- : Setting debug to False\n          root+- : Setting debug to False\n         root+-+ : Setting debug to False\n         root+-- : Setting debug to False\n           root- : Setting debug to False\n          root-+ : Setting debug to False\n         root-++ : Setting debug to False\n         root-+- : Setting debug to False\n        root-+-+ : Setting debug to False\n       root-+-++ : Setting debug to False\n       root-+-+- : Setting debug to False\n        root-+-- : Setting debug to False\n          root-- : Setting debug to False\n         root--+ : Setting debug to False\n         root--- : Setting debug to False\n        root---+ : Setting debug to False\n       root---++ : Setting debug to False\n       root---+- : Setting debug to False\n        root---- : Setting debug to False\n       root----+ : Setting debug to False\n       root----- : Setting debug to False\n"
     ]
    }
   ],
   "source": [
    "num_samples = 5\n",
    "\n",
    "for i in np.random.choice(test.shape[0], num_samples, replace=False):\n",
    "    print(\" Testing on a sample : test set index '%d'\"%i)\n",
    "    display(test.iloc[i])\n",
    "    result = root.classify(test.iloc[i])\n",
    "    print()\n",
    "    print(\" Classification result : %d, Label : %d\" % (result, test.iloc[i]['target']))\n",
    "    print()\n",
    "    \n",
    "root.set_debug(False, propagate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Test set : 4/60 were wrongly classified. \n Train set : 4/509 were wrongly classified. \n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "\n",
    "for i in test.index:\n",
    "    inp = test.loc[i]\n",
    "    out = root.classify(inp)\n",
    "    if(out != inp['target']):\n",
    "        error = error+1\n",
    "\n",
    "print(\" Test set : %d/%d were wrongly classified. \" % (error,test.shape[0]))\n",
    "\n",
    "error = 0\n",
    "\n",
    "for i in train.index:\n",
    "    inp = train.loc[i]\n",
    "    out = root.classify(inp)\n",
    "    if(out != inp['target']):\n",
    "        error = error+1\n",
    "\n",
    "print(\" Train set : %d/%d were wrongly classified. \" % (error,train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}