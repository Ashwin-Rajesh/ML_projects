{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbasecondae136968380ae4fcdb1cae1051555e6d5",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Decision trees on iris dataset\n",
    "\n",
    "The iris dataset contains sepal length, sepal width, petal length and petal width for classifying flowers between 3 classes. \n",
    "\n",
    "Here, we will be using decision trees to classify a given input into one of the 3 classes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn for only the dataset, pandas for managing the dataset and numpy for processing\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "data = load_iris()\n",
    "\n",
    "x = data['data']\n",
    "y = data['target']\n",
    "col_names = data['feature_names']\n",
    "\n",
    "x = pd.DataFrame(x, columns=col_names)\n",
    "x['target'] = y\n",
    "\n",
    "tgt_types = x.loc[(x['sepal length (cm)'] > 5)]['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Invalid parameters passed: {'train_set': 125}",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-828a72245ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Splitting the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ashwin/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid parameters passed: {'train_set': 125}"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset\n",
    "train, test = train_test_split(x, test_size=25, train_set=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(x, col_name=None, thresh_val=None, debug=False):\n",
    "    \n",
    "    if(col_name == None):\n",
    "        tot_no = x.shape[0]\n",
    "        class_loss = np.zeros((tgt_types.size,1))\n",
    "        \n",
    "        for i in range(tgt_types.size):\n",
    "            class_no = x.loc[x['target'] == tgt_types[i]].shape[0]\n",
    "            class_p  = class_no / tot_no\n",
    "            class_loss[i, 0] = class_p * (1 - class_p)\n",
    "\n",
    "        return sum(class_loss)\n",
    "\n",
    "    upper = x.loc[x[col_name] >  thresh_val]\n",
    "    lower = x.loc[x[col_name] <= thresh_val]\n",
    "\n",
    "\n",
    "    class_loss = np.zeros((tgt_types.size, 2))\n",
    "\n",
    "    upper_tot = upper.shape[0]   \n",
    "    lower_tot = lower.shape[0] \n",
    "\n",
    "    if(upper_tot == 0 or lower_tot == 0):\n",
    "        return 1\n",
    "\n",
    "    for i in range(tgt_types.size):\n",
    "        upper_cls_no = upper.loc[upper['target'] == tgt_types[i]].shape[0]\n",
    "        lower_cls_no = lower.loc[lower['target'] == tgt_types[i]].shape[0]\n",
    "        \n",
    "        upper_cls_p  = upper_cls_no / upper_tot\n",
    "        lower_cls_p  = lower_cls_no / lower_tot\n",
    "\n",
    "        class_loss[i, 0] = upper_cls_p * (1 - upper_cls_p)\n",
    "        class_loss[i, 1] = lower_cls_p * (1 - lower_cls_p)\n",
    "\n",
    "    gini = np.sum(class_loss, axis=0)\n",
    "\n",
    "    impurity = (upper_tot*gini[0]/x.shape[0]) + (lower_tot*gini[1]/x.shape[0])\n",
    "\n",
    "    if debug:\n",
    "        plt.scatter(upper[col_name], upper['target'], color=\"green\")\n",
    "        plt.scatter(lower[col_name], lower['target'], color=\"blue\")\n",
    "        plt.ylabel(\"Class\")\n",
    "        plt.xlabel(col_name)\n",
    "        plt.axline((thresh_val, 0), (thresh_val, 2))\n",
    "        plt.title(\"Split : %.2f, Impurity : %.3f\"%(thresh_val, impurity))\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, col_name, thresh):\n",
    "    upper = x.loc[x[col_name] > thresh].drop(col_name, axis=1)\n",
    "    lower = x.loc[x[col_name] <= thresh].drop(col_name, axis=1)\n",
    "\n",
    "    return (upper, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(x):\n",
    "    inputs = x.drop('target', axis=1)\n",
    "    outputs = x['target']\n",
    "    \n",
    "    min_impurity = 1\n",
    "    min_col = \"\"\n",
    "    min_thresh = -1\n",
    "\n",
    "    for col_name in inputs.columns:\n",
    "\n",
    "        values = x.sort_values(col_name)[col_name].unique()\n",
    "        thresholds = [(values[i]+values[i+1])/2 for i in range(values.shape[0]-1)]\n",
    "\n",
    "        for i in thresholds:\n",
    "            impurity = gini(x, col_name, i, False)\n",
    "\n",
    "            if(impurity < min_impurity):\n",
    "                min_impurity = impurity\n",
    "                min_col      = col_name\n",
    "                min_thresh   = i\n",
    "\n",
    "    return (min_impurity, min_col, min_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node():\n",
    "    def __init__(self, parent, level=None, name=None, debug=False):\n",
    "        self.parent = parent\n",
    "        \n",
    "        if(level == None):\n",
    "            if(parent == None):\n",
    "                self.level = 0\n",
    "            else:\n",
    "                self.level = parent.level + 1\n",
    "        else:\n",
    "            self.level = level\n",
    "        \n",
    "        self.leaf   = False             # Is this node a leaf node?\n",
    "        self.state  = None              # The output state (if a leaf node)\n",
    "        self.col    = None              # Threshold column name\n",
    "        self.thresh = 0                 # Threshold value\n",
    "        \n",
    "        self.upper  = None              # Upper child node\n",
    "        self.lower  = None              # Lower child node\n",
    "\n",
    "        self.debug  = debug             # If true, displays debug information\n",
    "\n",
    "        if(name == None):\n",
    "            if(parent == None):\n",
    "                self.name = \"root_node\"\n",
    "            else:\n",
    "                self.name = \"level%d_node\" % self.level\n",
    "        else:\n",
    "            self.name = name\n",
    "\n",
    "        if(debug):\n",
    "            print(\" %15s : Initialised node with level : %2d\" % (self.name, self.level))\n",
    "\n",
    "    # Turn the node into a leaf node, with set output\n",
    "    def make_leaf(self, output):\n",
    "        self.leaf  = True\n",
    "        self.state = output\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Made into leaf node, with output '%d'\" % (self.name, self.state))\n",
    "\n",
    "    # Train with data (set column and threshold). If the gini impurity has deteriorated or not improved, them the node is made a leaf node.\n",
    "    # If we do not want the node to be automatically turned into a leaf node, we can set force_branch to True\n",
    "    def train(self, x, force_branch=False):\n",
    "        data_impurity = gini(x)\n",
    "        impurity, self.col, self.thresh = find_best_split(x)\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Trained. Impurity before : %.2f, Impurity : %.2f, Column : '%s', Threshold : %.2f\" % (self.name, data_impurity, impurity, self.col, self.thresh))\n",
    "        \n",
    "        if(impurity >= data_impurity and not force_branch):\n",
    "            self.make_leaf(x.mode()['target'][0])\n",
    "            self.col    = None\n",
    "            self.thresh = None\n",
    "\n",
    "    # Split the data into two, if its not a leaf node\n",
    "    def split(self, x):\n",
    "        if(self.leaf):\n",
    "            if(self.debug):\n",
    "                print(\" %15s : Cant split, is a leaf node.\"%self.name)\n",
    "            return False\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Splitting input...\"%self.name)\n",
    "        \n",
    "        return split_data(x, self.col, self.thresh)\n",
    "    \n",
    "    # Attach the upper child node\n",
    "    def attach_upper(self, upper_node):\n",
    "        if(self.leaf):\n",
    "            print(\" %15s : Cant attach, is a leaf node\"%self.name)\n",
    "            return False\n",
    "        \n",
    "        self.upper = upper_node\n",
    "        return True\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Attached upper node '%s'\"%(self.name, self.upper.name))\n",
    "\n",
    "    # Attach the lower child node\n",
    "    def attach_lower(self, lower_node):\n",
    "        if(self.leaf):\n",
    "            print(\" %15s : Cant attach, is a leaf node\"%self.name)\n",
    "            return False\n",
    "\n",
    "        self.lower = lower_node\n",
    "        return True\n",
    "\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Attached upper node '%s'\"%(self.name, self.lower.name))\n",
    "\n",
    "    # Classify a given data sample\n",
    "    def classify(self, x):\n",
    "        if(self.leaf):\n",
    "            return self.state\n",
    "\n",
    "        if(x[self.col] > self.thresh):\n",
    "            if(self.debug):\n",
    "                print(\" %15s : Moving to upper node\"%self.name)\n",
    "            return self.upper.classify(x)\n",
    "        else:\n",
    "            if(self.debug):\n",
    "                print(\" %15s : Moving to lower node\"%self.name)\n",
    "            return self.lower.classify(x)\n",
    "\n",
    "    def make_children(self, debug=None):\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Making children nodes...\"%self.name)\n",
    "\n",
    "        if(debug==None):\n",
    "            debug=self.debug\n",
    "\n",
    "        upper = node(self, name='%s+'%(self.name), debug=debug)\n",
    "        lower = node(self, name='%s-'%(self.name), debug=debug)\n",
    "\n",
    "        self.attach_upper(upper)\n",
    "        self.attach_lower(lower)\n",
    "\n",
    "        return upper, lower\n",
    "\n",
    "    def train_children(self, x):\n",
    "        if(self.debug):\n",
    "            print(\" %15s : Training children\"%self.name)\n",
    "\n",
    "        upper_ds, lower_ds = self.split(x)\n",
    "        upper_gini, lower_gini = gini(upper_ds), gini(lower_ds)\n",
    "        \n",
    "        self.upper.train(upper_ds, upper_gini)\n",
    "        self.lower.train(lower_ds, lower_gini)\n",
    "\n",
    "    def get_children(self):\n",
    "        return self.upper, self.lower\n",
    "\n",
    "    def set_debug(self, debug=True, propagate=False):\n",
    "        if(self.debug != debug):\n",
    "            print(\" %15s : Setting debug to %s\"%(self.name, debug))\n",
    "        self.debug=debug\n",
    "        if(propagate):\n",
    "            if(not self.leaf):\n",
    "                self.upper.set_debug(debug, True)\n",
    "                self.lower.set_debug(debug, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurseive depth-first search, while building the tree\n",
    "def build_tree(data, level, root_node=None, debug=False):\n",
    "    if(level == 0):\n",
    "        leaf_out = data.mode()['target'][0]\n",
    "        root_node.make_leaf(leaf_out)\n",
    "        return\n",
    "    \n",
    "    if(root_node == None):\n",
    "        root_node = node(None, name='root', debug=debug)\n",
    "    \n",
    "    root_node.train(data)\n",
    "    \n",
    "    if(root_node.leaf):\n",
    "        return\n",
    "\n",
    "    root_node.make_children()\n",
    "    upper_ds, lower_ds = root_node.split(data)\n",
    "    \n",
    "    build_tree(upper_ds, level-1, root_node.upper)\n",
    "    build_tree(lower_ds, level-1, root_node.lower)\n",
    "\n",
    "    return root_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = build_tree(train, 2, debug=False)\n",
    "root.set_debug(False, propagate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Test set : 3/25 were wrongly classified. \n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "\n",
    "for i in test.index:\n",
    "    inp = test.loc[i]\n",
    "    out = root.classify(inp)\n",
    "    if(out != inp['target']):\n",
    "        error = error+1\n",
    "\n",
    "print(\" Test set : %d/%d were wrongly classified. \" % (error,test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Train set : 3/125 were wrongly classified. \n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "\n",
    "for i in train.index:\n",
    "    inp = train.loc[i]\n",
    "    out = root.classify(inp)\n",
    "    if(out != inp['target']):\n",
    "        error = error+1\n",
    "\n",
    "print(\" Train set : %d/%d were wrongly classified. \" % (error,train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}